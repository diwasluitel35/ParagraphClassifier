{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Neceessary Libraires\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding as DataCollator\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Read CSV Dataset\n",
    "\n",
    "df = pd.read_csv(r'dataset_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encode Categories into Numbers\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['labels'] = label_encoder.fit_transform(df['discourse_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to Hugging Face Dataset\n",
    "\n",
    "df = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defining Base Model Path\n",
    "\n",
    "model_path = 'microsoft/deberta-v3-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenizer and Preprocess Function Initialization\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "def preprocess(text):\n",
    "    inputs = text['discourse_text']\n",
    "    tokens = tokenizer(inputs, padding=False, max_length=256, truncation=True)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing and Tokenization\n",
    "\n",
    "tokenized_df = df.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Splitting the Dataset for Training and Evaluation\n",
    "\n",
    "split_dataset = tokenized_df.train_test_split(test_size=0.2, seed=42)\n",
    "train_df = split_dataset['train']\n",
    "test_df = split_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Computing Class Weights to Overcome Class Imbalance\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array([0,1,2,3,4,5,6]),\n",
    "    y=train_df[\"labels\"]\n",
    ")\n",
    "class_weights = torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom PyTorch Module For Attention Pooling\n",
    "\n",
    "class AttentionPooler(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        attention_scores = self.attention(last_hidden_state)\n",
    "        mask = attention_mask.unsqueeze(-1)\n",
    "        attention_scores[mask == 0] = -1e4\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        pooled_output = torch.sum(attention_weights * last_hidden_state, dim=1)\n",
    "        return pooled_output\n",
    "\n",
    "# Custom PyTorch Model\n",
    "\n",
    "class ParagraphClassifier(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model)\n",
    "        hidden = self.transformer.config.hidden_size\n",
    "        self.pooler = AttentionPooler(hidden_size=hidden)\n",
    "        self.classifier = nn.Linear(hidden, 7)\n",
    "\n",
    "        # Weighted Loss for Class Imbalance\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        out = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden = out.last_hidden_state\n",
    "        pooled = self.pooler(last_hidden_state=last_hidden, attention_mask=attention_mask)\n",
    "        logits = self.classifier(pooled)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        return {\"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dynamic Padding\n",
    "\n",
    "data_collator = DataCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Funtion for Metrics Calculation (Accuracy, F1-Macro)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc,\n",
    "            \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training Hyperparameters\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir='checkpoints',\n",
    "  save_strategy='epoch',\n",
    "  logging_strategy='epoch',\n",
    "  eval_strategy='epoch',\n",
    "  # Memory Optimization\n",
    "  per_device_train_batch_size=16,\n",
    "  per_device_eval_batch_size=16,\n",
    "  save_total_limit=4,\n",
    "  # Training\n",
    "  learning_rate=1e-5,\n",
    "  num_train_epochs=10,\n",
    "  weight_decay=0.02,\n",
    "  # Evaluation\n",
    "  metric_for_best_model='f1',\n",
    "  greater_is_better=True,\n",
    "  load_best_model_at_end=True,\n",
    "  # For GPU\n",
    "  fp16=True,\n",
    "  # Other\n",
    "  report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "model = ParagraphClassifier(model=model_path)\n",
    "\n",
    "# Defining Trainer\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  processing_class=tokenizer,\n",
    "  train_dataset=train_df,\n",
    "  eval_dataset=test_df,\n",
    "  compute_metrics=compute_metrics,\n",
    "  data_collator=data_collator,\n",
    "  callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8950791,
     "sourceId": 14062610,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
